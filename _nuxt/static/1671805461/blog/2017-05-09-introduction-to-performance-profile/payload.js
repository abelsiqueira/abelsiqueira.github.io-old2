__NUXT_JSONP__("/blog/2017-05-09-introduction-to-performance-profile", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J){return {data:[{page:{slug:"2017-05-09-introduction-to-performance-profile",title:s,date:"2017-05-09",tags:["work","performance","profile","optimization"],toc:[{id:t,depth:k,text:u},{id:v,depth:k,text:w},{id:x,depth:k,text:y},{id:z,depth:k,text:A}],body:{type:"root",children:[{type:b,tag:"h1",props:{id:"introduction-to-performance-profile"},children:[{type:b,tag:e,props:{href:"#introduction-to-performance-profile",ariaHidden:f,tabIndex:g},children:[{type:b,tag:h,props:{className:[i,j]},children:[]}]},{type:a,value:s}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The comparison of algorithms is an active area of work.\nWhen we start learning algorithms, or more advanced programming,\nwe learn of different ways of doing the same complex task.\nThe most usual first example is sorting, which introduces a series of\ndifferent ways to sort a single array, such as selection sort, insertion sort,\nquick sort, merge sort, etc.\nWhen comparing these algorithms, we take into account a few things:\nhow fast it is, how much memory it needs, what are the best\u002Fworst\u002Faverage-case\ncomplexities, and so on."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"However, in some areas, specially applied mathematics, we have an added\ncomplication: does the algorithm work? (Or does it work with a given budget?)\nThat happens because some types of problems don't have an algorithm that can\nsolve every problem. In particular, consider the problem of finding the minimum\nvalue of a function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ on a set\n$\\Omega \\subset \\mathbb{R}^n$. There are no algorithms that solve this problem\nfor any given $f$ and $\\Omega$, and even for specific, easier, cases, such as\nwhen $f$ is twice-continuously differentiable and $\\Omega = \\mathbb{R}^n$, it could\nhappen that the algorithm steps would take more time than allowed (or some other\nbudget contraint).\nIn these cases, we need another type of comparison between algorithms that take into\naccount the number of problems that are solved."}]},{type:a,value:c},{type:b,tag:l,props:{id:t},children:[{type:b,tag:e,props:{href:"#performance-profile",ariaHidden:f,tabIndex:g},children:[{type:b,tag:h,props:{className:[i,j]},children:[]}]},{type:a,value:u}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Described by Dolan and Moré [1] --"}]},{type:a,value:c},{type:b,tag:"blockquote",props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"(Edit: 08\u002F08\u002F2022) Professor André L. Tits brought to my attention the 1996 paper by Tits and Yang [3] that was already doing a profile comparison using a cumulative distribution of relative time."}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"-- the performance profile takes into account the\nnumber of problems solved as well as the cost it took to solve it. It scaled the\ncost of solving the problem according to the best solver for that problem.\nGiven a set of problems $P$ and a set of algorithms $S$, we define\n$c _ {s,p}$ as the cost of solving problem $p \\in P$ by algorithm $s \\in S$.\nIf algorithm can't solve the problem $p$, we define\n$c _ {s,p} = +\\infty$. We assume that at least one algorithm solves problem $p$.\nThe best algorithm for a given problem is the one that solves it with the least\ncost, i.e., we define"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"$$ c _ {\\min,p} = \\min _ {s\\in S} c _ {s,p}. $$"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Now we define the relative cost of the algorithm on a problem:"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"$$ r _ {s,p} = \\frac{ c _ {s,p} }{ c _ {\\min,p} }. $$"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Notice that $r _ {s,p} \\geq 1$, with $r _ {s,p} = 1$ meaning that algorithm\n$s$ is (one of) the best for problem $p$.\nFinally, the performance function of algorithm $s$ is given by"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"$$ P*s(t) = \\frac{ |\\{p \\in P \\mid\\ r * {s,p} \\leq t\\}| }{ |P| }. $$"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"See that $P_s(1)$ is the number of problems such that $r _ {s,p} = 1$, that is\nthe number of problems for which algorithm $s$ is one of the best.\nFurthermore, $P_s(r _ {\\max})$ is the number of problems solved by algorithm\n$s$, where"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"$$r _ {\\max} = \\max _ {s \\in S,\\ p \\in P} r _ {s,p}. $$"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The value $P_s(1)$ is called the efficiency of algorithm $s$ and $P_s(r _\n{\\max})$ is the robustness."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The following image shows an example of performance profile:"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:b,tag:B,props:{alt:C,src:"\u002Fblog\u002Fperprof-example.png"},children:[]},{type:a,value:m}]},{type:a,value:c},{type:b,tag:l,props:{id:v},children:[{type:b,tag:e,props:{href:"#example",ariaHidden:f,tabIndex:g},children:[{type:b,tag:h,props:{className:[i,j]},children:[]}]},{type:a,value:w}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"I'm gonna create a simple example. Suppose there are 30 problems and 3 solvers\nand the the following matrix stores the values of $c _ {s,p}$:"}]},{type:a,value:c},{type:b,tag:D,props:{className:[E]},children:[{type:b,tag:F,props:{className:[G,H]},children:[{type:b,tag:I,props:{},children:[{type:a,value:"c = rand(30, 3)\nc[rand(1:90, 10)] = Inf # To simulate failure\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The following code computes the minimum, the ratios and the performance\nfunction plots:"}]},{type:a,value:c},{type:b,tag:D,props:{className:[E]},children:[{type:b,tag:F,props:{className:[G,H]},children:[{type:b,tag:I,props:{},children:[{type:a,value:"cmin = minimum(c, 2)\nR = c .\u002F cmin\nt = sort(unique(R))\nif t[end] == Inf\n  pop!(t)\nend\nplot(xaxis=:log)\nfor i = 1:size(c, 2)\n  plot!(t, [sum(R[:,i] .\u003C= ti)\u002Fsize(c,1) for ti in t], label=\"Alg $i\", t=:steppre, lw=2)\nend\nylims!(0, 1)\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The resulting image is"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:b,tag:B,props:{alt:C,src:"\u002Fblog\u002Fperprof-julia.png"},children:[]},{type:a,value:m}]},{type:a,value:c},{type:b,tag:l,props:{id:x},children:[{type:b,tag:e,props:{href:"#implementations",ariaHidden:f,tabIndex:g},children:[{type:b,tag:h,props:{className:[i,j]},children:[]}]},{type:a,value:y}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"The traditional implementation of the performance profile was in MatLab, but I\ncan't find it now. Let me know if you have a link to it, so I'll add here."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Another implementation was made by me, Raniere Gaia, and Luiz-Rafael Santos [2],\nin Python, but works as an external program too.\nWe haven't updated it in a while. Contact me if you're interested in helping.\nHere's the "},{type:b,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002Fufpr-opt\u002Fperprof-py",rel:[n,o,p],target:q},children:[{type:a,value:"link"}]},{type:a,value:m}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Last, but not least, there is an implementation in Julia made by Dominique Orban,\nwhich is part of the\n"},{type:b,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002FJuliaSmoothOptimizers",rel:[n,o,p],target:q},children:[{type:a,value:"JuliaSmoothOptimizers"}]},{type:a,value:" organization.\nThe direct link is\n"},{type:b,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002FJuliaSmoothOptimizers\u002FBenchmarkProfiles.jl",rel:[n,o,p],target:q},children:[{type:a,value:"here"}]},{type:a,value:m}]},{type:a,value:c},{type:b,tag:l,props:{id:z},children:[{type:b,tag:e,props:{href:"#references",ariaHidden:f,tabIndex:g},children:[{type:b,tag:h,props:{className:[i,j]},children:[]}]},{type:a,value:A}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"[1] Elizabeth D. Dolan and Jorge J. Moré. Benchmarking optimization software\nwith performance profiles.\n"},{type:b,tag:r,props:{},children:[{type:a,value:"Mathematical Programming"}]},{type:a,value:", 91(2):201-213, 2002.\nDOI: 10.1007\u002Fs101070100263."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"[2] A. S. Siqueira, R. G. Costa da Silva, and L.-R. Santos.\nPerprof-py: A Python Package for Performance Profile of Mathematical\nOptimization Software.\n"},{type:b,tag:r,props:{},children:[{type:a,value:"Journal of Open Research Software"}]},{type:a,value:", 4(1), p.e12, 2016.\nDOI: 10.5334\u002Fjors.81."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"[3] A.L. Tits and Y. Yang.\nGlobally convergent algorithms for robust pole placement by state feedback.\n"},{type:b,tag:r,props:{},children:[{type:a,value:"IEEE Transactions on Automatic Control"}]},{type:a,value:", 41(10):1432-1452, 1996.\nDOI: 10.1109\u002F9.539425."}]}]},dir:"\u002Fblog",path:"\u002Fblog\u002F2017-05-09-introduction-to-performance-profile",extension:".md",createdAt:J,updatedAt:J,bodyPlainText:"\n# Introduction to Performance Profile\n\nThe comparison of algorithms is an active area of work.\nWhen we start learning algorithms, or more advanced programming,\nwe learn of different ways of doing the same complex task.\nThe most usual first example is sorting, which introduces a series of\ndifferent ways to sort a single array, such as selection sort, insertion sort,\nquick sort, merge sort, etc.\nWhen comparing these algorithms, we take into account a few things:\nhow fast it is, how much memory it needs, what are the best\u002Fworst\u002Faverage-case\ncomplexities, and so on.\n\nHowever, in some areas, specially applied mathematics, we have an added\ncomplication: does the algorithm work? (Or does it work with a given budget?)\nThat happens because some types of problems don't have an algorithm that can\nsolve every problem. In particular, consider the problem of finding the minimum\nvalue of a function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ on a set\n$\\Omega \\subset \\mathbb{R}^n$. There are no algorithms that solve this problem\nfor any given $f$ and $\\Omega$, and even for specific, easier, cases, such as\nwhen $f$ is twice-continuously differentiable and $\\Omega = \\mathbb{R}^n$, it could\nhappen that the algorithm steps would take more time than allowed (or some other\nbudget contraint).\nIn these cases, we need another type of comparison between algorithms that take into\naccount the number of problems that are solved.\n\n### Performance Profile\n\nDescribed by Dolan and Moré [1] --\n\n\u003E (Edit: 08\u002F08\u002F2022) Professor André L. Tits brought to my attention the 1996 paper by Tits and Yang [3] that was already doing a profile comparison using a cumulative distribution of relative time.\n\n-- the performance profile takes into account the\nnumber of problems solved as well as the cost it took to solve it. It scaled the\ncost of solving the problem according to the best solver for that problem.\nGiven a set of problems $P$ and a set of algorithms $S$, we define\n$c _ {s,p}$ as the cost of solving problem $p \\in P$ by algorithm $s \\in S$.\nIf algorithm can't solve the problem $p$, we define\n$c _ {s,p} = +\\infty$. We assume that at least one algorithm solves problem $p$.\nThe best algorithm for a given problem is the one that solves it with the least\ncost, i.e., we define\n\n$$ c _ {\\min,p} = \\min _ {s\\in S} c \\_ {s,p}. $$\n\nNow we define the relative cost of the algorithm on a problem:\n\n$$ r _ {s,p} = \\frac{ c _ {s,p} }{ c \\_ {\\min,p} }. $$\n\nNotice that $r _ {s,p} \\geq 1$, with $r _ {s,p} = 1$ meaning that algorithm\n$s$ is (one of) the best for problem $p$.\nFinally, the performance function of algorithm $s$ is given by\n\n$$ P*s(t) = \\frac{ |\\\\{p \\in P \\mid\\ r * {s,p} \\leq t\\\\}| }{ |P| }. $$\n\nSee that $P_s(1)$ is the number of problems such that $r _ {s,p} = 1$, that is\nthe number of problems for which algorithm $s$ is one of the best.\nFurthermore, $P_s(r _ {\\max})$ is the number of problems solved by algorithm\n$s$, where\n\n$$r _ {\\max} = \\max _ {s \\in S,\\ p \\in P} r _ {s,p}. $$\n\nThe value $P_s(1)$ is called the efficiency of algorithm $s$ and $P_s(r _\n{\\max})$ is the robustness.\n\nThe following image shows an example of performance profile:\n\n![](\u002Fblog\u002Fperprof-example.png).\n\n### Example\n\nI'm gonna create a simple example. Suppose there are 30 problems and 3 solvers\nand the the following matrix stores the values of $c _ {s,p}$:\n\n```\nc = rand(30, 3)\nc[rand(1:90, 10)] = Inf # To simulate failure\n```\n\nThe following code computes the minimum, the ratios and the performance\nfunction plots:\n\n```\ncmin = minimum(c, 2)\nR = c .\u002F cmin\nt = sort(unique(R))\nif t[end] == Inf\n  pop!(t)\nend\nplot(xaxis=:log)\nfor i = 1:size(c, 2)\n  plot!(t, [sum(R[:,i] .\u003C= ti)\u002Fsize(c,1) for ti in t], label=\"Alg $i\", t=:steppre, lw=2)\nend\nylims!(0, 1)\n```\n\nThe resulting image is\n\n![](\u002Fblog\u002Fperprof-julia.png).\n\n### Implementations\n\nThe traditional implementation of the performance profile was in MatLab, but I\ncan't find it now. Let me know if you have a link to it, so I'll add here.\n\nAnother implementation was made by me, Raniere Gaia, and Luiz-Rafael Santos [2],\nin Python, but works as an external program too.\nWe haven't updated it in a while. Contact me if you're interested in helping.\nHere's the [link](https:\u002F\u002Fgithub.com\u002Fufpr-opt\u002Fperprof-py).\n\nLast, but not least, there is an implementation in Julia made by Dominique Orban,\nwhich is part of the\n[JuliaSmoothOptimizers](https:\u002F\u002Fgithub.com\u002FJuliaSmoothOptimizers) organization.\nThe direct link is\n[here](https:\u002F\u002Fgithub.com\u002FJuliaSmoothOptimizers\u002FBenchmarkProfiles.jl).\n\n### References\n\n[1] Elizabeth D. Dolan and Jorge J. Moré. Benchmarking optimization software\nwith performance profiles.\n_Mathematical Programming_, 91(2):201-213, 2002.\nDOI: 10.1007\u002Fs101070100263.\n\n[2] A. S. Siqueira, R. G. Costa da Silva, and L.-R. Santos.\nPerprof-py: A Python Package for Performance Profile of Mathematical\nOptimization Software.\n_Journal of Open Research Software_, 4(1), p.e12, 2016.\nDOI: 10.5334\u002Fjors.81.\n\n[3] A.L. Tits and Y. Yang.\nGlobally convergent algorithms for robust pole placement by state feedback.\n_IEEE Transactions on Automatic Control_, 41(10):1432-1452, 1996.\nDOI: 10.1109\u002F9.539425.\n"},prev:{slug:"2018-07-04-my-experience-in-the-jump-dev-annual-workshop",title:"My experience in the JuMP-dev annual workshop"},next:{slug:"2017-03-13-installing-gurobi-7-on-linux",title:"Installing Gurobi 7 on Linux"}}],fetch:{},mutations:void 0}}("text","element","\n","p","a","true",-1,"span","icon","icon-link",3,"h3",".","nofollow","noopener","noreferrer","_blank","em","Introduction to Performance Profile","performance-profile","Performance Profile","example","Example","implementations","Implementations","references","References","img","","div","nuxt-content-highlight","pre","language-text","line-numbers","code","2022-12-23T14:23:08.544Z")));