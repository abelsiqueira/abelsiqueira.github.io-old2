<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Abel Soares Siqueira</title>
        <link>https://abelsiqueira.github.io/tag/cutest/feed.xml</link>
        <description>RSS feed for abelsiqueira.github.io</description>
        <lastBuildDate>Fri, 23 Dec 2022 17:40:54 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/nuxt-community/feed-module</generator>
        <category>Nuxt.js</category>
        <item>
            <title><![CDATA[NLPModels.jl and CUTEst.jl: Constrained optimization]]></title>
            <link>https://abelsiqueira.github.io/blog/2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization</link>
            <guid>https://abelsiqueira.github.io/blog/2017-02-17-nlpmodelsjl-and-cutestjl-constrained-optimization</guid>
            <pubDate>Fri, 17 Feb 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# NLPModels.jl and CUTEst.jl&#58; Constrained optimization

This is a continuation of [this
post](https://abelsiqueira.github.io{{local_prefix}}nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/).
And again, you can follow the commands of this post in the
[asciinema](https://asciinema.org/a/103654).

If you followed along last post, you should know the basics of our
NLPModels API, including CUTEst access.

One thing I didn't explore, though, was constrained problems.
It'd complicate too much.

However, now that we know how to handle the basics, we can move to the
advanced.

**Nonlinear Programming format**

The NLPModels internal structure is based on the CUTEst way of storing a
problem.
We use the following form for the optimization problem:

$$
\begin{align}
\min \quad & f(x) \\
s.t. \quad & c_L \leq c(x) \leq c_U \\
& \ell \leq x \leq u\end{align}
$$

Given an `AbstractNLPModel` named `nlp`, the values for $\ell$, $u$, $c_L$ and
$c_U$ are stored in an `NLPModelMeta` structure, and can be accessed by
through `nlp.meta`.

Let's look back at the simple Rosenbrock problem of before.

```
using NLPModels

f(x) = (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2
x0 = [-1.2; 1.0]
nlp = ADNLPModel(f, x0)
print(nlp.meta)
```

You should be seeing this:

```
Minimization problem Generic
nvar = 2, ncon = 0 (0 linear)
lvar = -Inf  -Inf
uvar = Inf  Inf
lcon = ∅
ucon = ∅
x0 = -1.2  1.0
y0 = ∅
nnzh = 4
nnzj = 0
```

Although the meaning of these values is reasonably straigthforward, I'll explain a bit.

- `nvar` is the number of variables in a problem;
- `ncon` is the number of constraints, without counting the bounds;
- `lvar` is the vector $\ell$, the lower bounds on the variables;
- `uvar` is the vector $u$, the upper bounds on the variables;
- `lcon` is the vector $c_L$, the lower bounds of the constraints function;
- `ucon` is the vector $c_U$, the upper bounds of the constraints function;
- `x0` is the initial approximation to the solution, aka the starting point;
- `y0` is the initial approximation to the Lagrange multipliers;
- `nnzh` is the number of nonzeros on the Hessian¹;
- `nnzj` is the number of nonzeros on the Jacobian¹;

_¹ `nnzh` and `nnzj` are not consistent between models, because some consider the dense matrix, and for the Hessian, some consider only the triangle. However, if you're possibly considering using `nnzh`, you're probably looking for `hess_coord` too, and `hess_coord` returns with the correct size._

These values can be accessed directly as fields in `meta` with the same name above.

```
nlp.meta.ncon
nlp.meta.x0
nlp.meta.lvar
```

**Bounds**

Now, let's create a bounded problem.

```
nlp = ADNLPModel(f, x0, lvar=zeros(2), uvar=[0.4; 0.6])
print(nlp.meta)
```

Now the bounds are set, and you can access them with

```
nlp.meta.lvar
nlp.meta.uvar
```

That's pretty much it. For `SimpleNLPModel`, it's the same thing.
`MathProgNLPModel` inherits the bounds, as expected:

```
using JuMP

jmp = Model()
u = [0.4; 0.6]
@variable(jmp, 0 <= x[i=1:2] <= u[i], start=(x0[i]))
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
mpbnlp = MathProgNLPModel(jmp)
print(mpbnlp.meta)
```

For CUTEst, there is no differentiation on creating a problem with bounds or
not, since it uses the internal description of the problem.
For instance, `HS4` is a bounded problem.

```
using CUTEst

clp = CUTEstModel("HS4")
print(clp.meta)
finalize(clp)
```

Notice that it can happen that one or more of the variables is unlimited
(lower, upper or both). This is represented by the value `Inf` in Julia.
This should be expected since the unconstrained problem already used these
`Inf` values.

On the other hand, it could happen that $\ell_i = u_i$, in which case the
variable is fixed, or that $\ell_i > u_i$, in which case the variable (and the
problem) is infeasible.
Note that `NLPModels` only creates the model, it doesn't check whether it is
feasible or not, even in this simple example. That said, CUTEst shouldn't have
any infeasible variable.

Furthermore, all these types of bounds can be accessed from `meta`. Notice that
there are 6 possible situations:

- Free variables, stored in `meta.ifree`;
- Fixed variables, stored in `meta.ifix`;
- Variables bounded below, stored in `meta.ilow`;
- Variables bounded above, stored in `meta.iupp`;
- Variables bounded above and below, stored in `meta.irng`;
- Infeasible variables, stored in `meta.iinf`.

Here is one example with one of each of them

```
nlp = ADNLPModel(x->dot(x,x), zeros(6),
  lvar = [-Inf, -Inf, 0.0, 0.0, 0.0,  0.0],
  uvar = [ Inf,  1.0, Inf, 1.0, 0.0, -1.0])
nlp.meta.ifree
nlp.meta.ifix
nlp.meta.ilow
nlp.meta.iupp
nlp.meta.irng
nlp.meta.iinf
```

**Constraints**

Constraints are stored in NLPModels following in the format $c_L \leq c(x) \leq c_U$.
That means that an equality constraint happens when $c_{L_j} = c_{U_j}$.
Let's look at how to create a problem with constraints.

For `ADNLPModel`, you need to pass three keywords arguments: `c`, `lcon` and `ucon`,
which represent $c(x)$, $c_L$ and $c_U$, respectively.
For instance, the problem

$$
\begin{align}
\min \quad & x_1^2 + x_2^2 \\
s.t. \quad & x_1 + x_2 = 1
\end{align}
$$

is created by doing

```
c(x) = [x[1] + x[2] - 1]
lcon = [0.0]
ucon = [0.0]
nlp = ADNLPModel(x->dot(x,x), zeros(2), c=c, lcon=lcon, ucon=ucon)
```

or alternatively, if you don't want the intermediary functions

```
nlp = ADNLPModel(x->dot(x,x), zeros(2), c=x->[x[1]+x[2]-1], lcon=[0.0], ucon=[0.0])
```

Another possibility is to do

```
nlp = ADNLPModel(x->dot(x,x), zeros(2), c=x->[x[1]+x[2]], lcon=[1.0], ucon=[1.0])
```

Personally, I prefer the former.

For inequalities, you can have only lower, only upper, and both.
The commands

```
nlp = ADNLPModel(x->dot(x,x), zeros(2),
  c=x->[x[1] + x[2]; 3x[1] + 2x[2]; x[1]*x[2]],
  lcon = [-1.0; -Inf; 1.0],
  ucon = [Inf;   3.0; 2.0])
```

implement the problem

$$
\begin{align}
\min \quad & x_1^2 + x_2^2 \\
s.t. \quad & x_1 + x_2 \geq -1 \\
& 3x_1 + 2x_2 \leq 3 \\
& 1 \leq x_1x_2 \leq 2.
\end{align}
$$

Again, the types of constraints can be accessed in `meta`, through
`nlp.meta.jfix`, `jfree`, `jinf`, `jlow`, `jrng` and `jupp`.
Notice if you forget to set `lcon` and `ucon`, there will be no
constraints, even though `c` is set. This is because the number of
constraints is taken from the lenght of these vectors.

Now, to access these constraints, let's consider this simple problem.

```
nlp = ADNLPModel(f, x0, c=x->[x[1]*x[2] - 0.5], lcon=[0.0], ucon=[0.0])
```

The function `cons` return $c(x)$.

```
cons(nlp, nlp.meta.x0)
```

The function `jac` returns the Jacobian of $c$. `jprod` and `jtprod` the
Jacobian product times a vector, and `jac_op` the LinearOperator.

```
jac(nlp, nlp.meta.x0)
jprod(nlp, nlp.meta.x0, ones(2))
jtprod(nlp, nlp.meta.x0, ones(1))
J = jac_op(nlp, nlp.meta.x0)
J * ones(2)
J' * ones(1)
```

To get the Hessian we'll use the same functions as the unconstrained case,
with the addition of a keyword parameter `y`.

```
y = [1e4]
hess(nlp, nlp.meta.x0, y=y)
hprod(nlp, nlp.meat.x0, ones(2))
H = hess_op(nlp, nlp.meta.x0, y=y)
H * ones(2)
```

If you want to ignore the objective function, or scale it by some value,
you can use the keyword parameter `obj_weight`.

```
s = 0.0
hess(nlp, nlp.meta.x0, y=y, obj_weight=s)
hprod(nlp, nlp.meat.x0, ones(2), obj_weight=s)
H = hess_op(nlp, nlp.meta.x0, y=y, obj_weight=s)
H * ones(2)
```

Check the
[API](http://juliasmoothoptimizers.github.io/NLPModels.jl/stable/api.html)
for more details.

We can also create a constrained JuMP model.

```
x0 = [-1.2; 1.0]
jmp = Model()
@variable(jmp, x[i=1:2], start=(x0[i]))
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
@NLcontraint(jmp, x[1]*x[2] == 0.5)
mpbnlp = MathProgNLPModel(jmp)
cons(mpbnlp, mpbnlp.meta.x0)
jac(mpbnlp, mpbnlp.meta.x0)
hess(mpbnlp, mpbnlp.meta.x0, y=y)
```

And again, the access in CUTEst problems is the same.

```
clp = CUTEstModel("BT1")
cons(clp, clp.meta.x0)
jac(clp, clp.meta.x0)
hess(clp, clp.meta.x0, y=clp.meta.y0)
finalize(clp)
```

**Convenience functions**

There are some convenience functions to check whether a problem has only
equalities, only bounds, etc.
For clarification, we're gonna say function constraint to refer to constraints that are not bounds.

- `has_bounds`: Returns `true` is variable has bounds.
- `bound_constrained`: Returns `true` if `has_bounds` and no function
  constraints;
- `unconstrained`: No function constraints nor bounds;
- `linearly_constrained`: There are function constraints, and they are
  linear; _obs: even though a `bound_constrained` problem is linearly
  constrained, this will return false_.
- `equality_constrained`: There are function constraints, and they are all equalities;
- `inequality_constrained`: There are function constraints, and they are all inequalities;

**Example solver**

Let's implement a "simple" solver for constrained optimization.
Our solver will loosely follow the Byrd-Omojokun implementation of

> M. Lalee, J. Nocedal, and T. Plantenga. **On the implementation of an algorithm for large-scale equality constrained optimization**. SIAM J. Optim., Vol. 8, No. 3, pp. 682-706, 1998.

```
function solver(nlp :: AbstractNLPModel)
  if !equality_constrained(nlp)
    error("This solver is for equality constrained problems")
  elseif has_bounds(nlp)
    error("Can't handle bounds")
  end

  x = nlp.meta.x0

  fx = obj(nlp, x)
  cx = cons(nlp, x)

  ∇fx = grad(nlp, x)
  Jx = jac_op(nlp, x)

  λ = cgls(Jx', -∇fx)[1]
  ∇ℓx = ∇fx + Jx'*λ
  norm∇ℓx = norm(∇ℓx)

  Δ = max(0.1, min(100.0, 10norm∇ℓx))
  μ = 1
  v = zeros(nlp.meta.nvar)

  iter = 0
  while (norm∇ℓx > 1e-4 || norm(cx) > 1e-4) && (iter < 10000)
    # Vertical step
    if norm(cx) > 1e-4
      v = cg(Jx'*Jx, -Jx'*cx, radius=0.8Δ)[1]
      Δp = sqrt(Δ^2 - dot(v,v))
    else
      fill!(v, 0)
      Δp = Δ
    end

    # Horizontal step
    # Simplified to consider only ∇ℓx = proj(∇f, Nu(A))
    B = hess_op(nlp, x, y=λ)
    B∇ℓx = B * ∇ℓx
    gtBg = dot(∇ℓx, B∇ℓx)
    gtγ = dot(∇ℓx, ∇fx + B * v)
    t = if gtBg <= 0
      norm∇ℓx > 0 ? Δp/norm∇ℓx : 0.0
    else
      t = min(gtγ/gtBg, Δp/norm∇ℓx)
    end

    d = v - t * ∇ℓx

    # Trial step acceptance
    xt = x + d
    ft = obj(nlp, xt)
    ct = cons(nlp, xt)
    γ = dot(d, ∇fx) + 0.5*dot(d, B * d)
    θ = norm(cx) - norm(Jx * d + cx)
    normλ = norm(λ, Inf)
    if θ <= 0
      μ = normλ
    elseif normλ > γ/θ
      μ = min(normλ, 0.1 + γ/θ)
    else
      μ = 0.1 + γ/θ
    end
    Pred = -γ + μ * θ
    Ared = fx - ft + μ * (norm(cx) - norm(ct))

    ρ = Ared/Pred
    if ρ > 1e-2
      x .= xt
      fx = ft
      cx .= ct
      ∇fx = grad(nlp, x)
      Jx = jac_op(nlp, x)
      λ = cgls(Jx', -∇fx)[1]
      ∇ℓx = ∇fx + Jx'*λ
      norm∇ℓx = norm(∇ℓx)
      if ρ > 0.75 && norm(d) > 0.99Δ
        Δ *= 2.0
      end
    else
      Δ *= 0.5
    end

    iter += 1
  end

  return x, fx, norm∇ℓx, norm(cx)
end
```

Too loosely, in fact.

- The horizontal step computes only the Cauchy step;
- No special updates;
- No second-order correction;
- No efficient implementation beyond the easy-to-do.

To test how good it is, let's run on the Hock-Schittkowski constrained problems.

```
function runcutest()
  problems = filter(x->contains(x, "HS") && length(x) <= 5, CUTEst.select(only_free_var=true, only_equ_con=true))
  sort!(problems)
  @printf("%-7s  %15s  %15s  %15s\n",
          "Problem", "f(x)", "‖∇ℓ(x,λ)‖", "‖c(x)‖")
  for p in problems
    nlp = CUTEstModel(p)
    try
      x, fx, nlx, ncx = solver(nlp)
      @printf("%-7s  %15.8e  %15.8e  %15.8e\n", p, fx, nlx, ncx)
    catch
      @printf("%-7s  %s\n", p, "failure")
    finally
      finalize(nlp)
    end
  end
end
```

I'm gonna print the output of this one, so you can compare it with yours.

```
Problem             f(x)        ‖∇ℓ(x,λ)‖           ‖c(x)‖
HS26      5.15931251e-07   9.88009545e-05   5.24359322e-05
HS27      4.00000164e-02   5.13264248e-05   2.26312672e-09
HS28      7.00144545e-09   9.46563681e-05   2.44249065e-15
HS39     -1.00000010e+00   1.99856691e-08   1.61607518e-07
HS40     -2.50011760e-01   4.52797064e-05   2.53246505e-05
HS42      1.38577292e+01   5.06661945e-05   5.33092868e-05
HS46      3.56533430e-06   9.98827045e-05   8.00086215e-05
HS47      3.53637757e-07   9.71339790e-05   7.70496596e-05
HS48      4.65110036e-10   4.85457139e-05   2.27798719e-15
HS49      3.14248189e-06   9.94899395e-05   2.27488138e-13
HS50      1.36244906e-12   2.16913725e-06   2.90632554e-14
HS51      1.58249170e-09   8.52213221e-05   6.52675179e-15
HS52      5.32664756e+00   3.35626559e-05   3.21155766e-14
HS56     -3.45604528e+00   9.91076239e-05   3.14471179e-05
HS6       5.93063756e-13   6.88804464e-07   9.61311292e-06
HS61     -1.43646176e+02   1.06116455e-05   1.80421875e-05
HS7      -1.73205088e+00   1.23808109e-11   2.60442422e-07
HS77      2.41501014e-01   8.31210333e-05   7.75367223e-05
HS78     -2.91972281e+00   2.27102179e-05   2.88776440e-05
HS79      7.87776482e-02   4.77319205e-05   7.55827729e-05
HS8      -1.00000000e+00   0.00000000e+00   2.39989802e-06
HS9      -5.00000000e-01   1.23438228e-06   3.55271368e-15
```

If you compare against the Hock-Schitkowski paper, you'll see that
the method converged for all 22 problems.
Considering our simplifications, this is a very exciting.

That's all for now. Use our RSS feed to keep updated.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia]]></title>
            <link>https://abelsiqueira.github.io/blog/2017-02-07-nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia</link>
            <guid>https://abelsiqueira.github.io/blog/2017-02-07-nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia</guid>
            <pubDate>Tue, 07 Feb 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# NLPModels.jl, CUTEst.jl and other Nonlinear Optimization Packages on Julia

A couple of weeks ago me and Professor [Dominique Orban](https://dpo.github.io) have finally made a release of
CUTEst.jl, a wrapper for the CUTEst repository of problems for nonlinear
optimization (which I've mentioned before).
Along with this release, we've done a release of NLPModels.jl, the underlying
package. I think it's time I explain a little about these packages, others,
and how to use them together.
If you want to see the output of the commands, you can open
[this ASCIInema](https://asciinema.org/a/102371)
side by side.

_Obs.: Tutorial using Julia 0.5.0_

_Edit: Second part is
[here](https://abelsiqueira.github.io{{local_prefix}}nlpmodelsjl-and-cutestjl-constrained-optimization/)._

**JuliaSmoothOptimizers**
[![JuliaSmoothOptimizers logo](https://juliasmoothoptimizers.github.io/assets/logo.png){: .img-view }](https://juliasmoothoptimizers.github.io)

Most packages mentioned here will be a part of the JuliaSmoothOptimizers (JSO)
organization. There are more packages in the organization that I won't mention here, but you should check it out.

**NLPModels.jl**

NLPModels is a package for creating Nonlinear Optimization Models. It is
focused on the needs of the solver writer, such as the ability to write one
solver that works on many models.
The package defines a few models, and there are others on the horizon.
The ones already done are:

- **ADNLPModel**: A model with automatic differentiation;
- **MathProgNLPModel**: A model for [MathProgBase](https://github.com/JuliaOpt/MathProgBase.jl)/[JuMP](http://github.com/JuliaOpt/JuMP.jl) conversion, whose utility will be shown below (obs: MPB and JuMP are packages from the JuliaOpt organization);
- **SimpleNLPModel**: A model in which nothing is automatic, i.e., all functions have to be provided by the user.
- **SlackModel**: A model that changes all inequalities to equalities adding extra variables;
- **LBFGSModel** and **LSR1Model**: Models that create quasi-Newton models from another model.

The first two models are designed to be easy to use; the third is useful for
efficient model creation in specific cases; the last ones are utility models.

Let's begin by installing NLPModels.jl, and a couple of optional requirements.

```
Pkg.add("NLPModels.jl")
Pkg.add("JuMP.jl") # Installs ForwardDiff also.
```

This should install version 0.1.0. After that, just do

```
using NLPModels
```

Now, let's create a simple function: Rosenbrock's.

```
f(x) = (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2
```

The Rosenbrock problem traditionally starts from $(-1.2,1.0)$.

```
x0 = [-1.2; 1.0]
```

Now, we are ready to create the problem.

```
adnlp = ADNLPModel(f, x0)
```

Now, we can access the function and derivatives using the [NLPModels API](https://juliasmoothoptimizers.github.io/NLPModels.jl/stable/api.html)

```
obj(adnlp, adnlp.meta.x0)
grad(adnlp, adnlp.meta.x0)
hess(adnlp, adnlp.meta.x0)
objgrad(adnlp, adnlp.meta.x0)
hprod(adnlp, adnlp.meta.x0, ones(2))
H = hess_op(adnlp, adnlp.meta.x0)
H * ones(2)
```

At this point, we can't differentiate many things from simply using
`ForwardDiff` interface directly, but two things stand out: `objgrad` returns
both functions at once, and `hess_op` returns a
[LinearOperator](https://github.com/JuliaSmoothOptimizers/LinearOperators.jl),
another structure created in JuliaSmoothOptimizers.
This one defines a linear operator, extending Julia matrices in the sense that if

```
using LinearOperators
n = 100
A = rand(n, n)
B = rand(n, n)
opA = LinearOperator(A)
opB = LinearOperator(B)
v = rand(n)
```

then `(A * B) * v` computes the matrix product, whereas `(opA * opB) * v` won't.
Furthermore, the linear operator can be created from the functions
`v->Mp(v)` and `v->Mtp(v)`, defining the product of the linear operator times a vector and its transpose times a vector.

```
T = LinearOperator(2, 2, # sizes
                   false, false,
                   v->[-v[2]; v[1]], v->[v[2]; -v[1]])
v = rand(2)
T * v
T' * v
```

_Obs: In the `ADNLPModel` case, `hess_op` returns a linear operator that is actually
computing the matrix, but this is a issue to be tackled on the future (PRs
welcome). But we'll be back with uses for `hess_op` soon._

The next model is the `MathProgNLPModel`. This model's main use is the `JuMP`
modelling language. This is very useful for more elaborate writing, specially
with constraints. It does create a little more overhead though, so keep that
in mind.

```
using JuMP
jmp = Model()
@variable(jmp, x[i=1:2], start=(x0[i])) # x0 from before
@NLobjective(jmp, Min, (x[1] - 1)^2 + 100*(x[2] - x[1]^2)^2)
mpbnlp = MathProgNLPModel(jmp)
```

Try the commands again.

```
obj(mpbnlp, mpbnlp.meta.x0)
grad(mpbnlp, mpbnlp.meta.x0)
hess(mpbnlp, mpbnlp.meta.x0)
objgrad(mpbnlp, mpbnlp.meta.x0)
hprod(mpbnlp, mpbnlp.meta.x0, ones(2))
H = hess_op(mpbnlp, mpbnlp.meta.x0)
H * ones(2)
```

It should be pretty much the same, though there is a little difference in `hess`.
JuMP creates the sparse Hessian, which is better, from a computational point of
view.

Notice how the commands are the same. I've actually copy-pasted the commands
from above.
This allows the write of a solver in just a couple of commands.
For instance, a simple **Newton method**.

```
function newton(nlp :: AbstractNLPModel)
  x = nlp.meta.x0
  fx = obj(nlp, x)
  gx = grad(nlp, x)
  ngx = norm(gx)
  while ngx > 1e-6
    Hx = hess(nlp, x)
    d = -gx
    try
      G = chol(Hermitian(Hx, :L)) # Make Cholesky work on lower-only matrix.
      d = -G\(G'\gx)
    catch e
      if !isa(e, Base.LinAlg.PosDefException); rethrow(e); end
    end
    t = 1.0
    xt = x + t * d
    ft = obj(nlp, xt)
    while ft > fx + 0.5 * t * dot(gx, d)
      t *= 0.5
      xt = x + t * d
      ft = obj(nlp, xt)
    end
    x = xt
    fx = ft
    gx = grad(nlp, x)
    ngx = norm(gx)
  end
  return x, fx, ngx
end
```

And we run in the problems with

```
newton(adnlp)
newton(mpbnlp)
```

_Write once, use on problems from different sources._

Now, to have more fun, let's get another package:
[OptimizationProblems.jl](https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl).
This package doesn't have a release yet, so we have to clone it:

```
Pkg.clone("https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl")
```

What we have here is a collection of JuMP models implementing some of the
CUTEst problems. Together with `NLPModels.jl`, we have a good opportunity to test our Newton implementation.

```
using OptimizationProblems

x, fx, ngx = newton(MathProgNLPModel( rosenbrock() ))
x, fx, ngx = newton(MathProgNLPModel( dixmaanj() ))
x, fx, ngx = newton(MathProgNLPModel( brownbs() ))
```

_An issue with OptimizationProblems is that it still doesn't have a way to get
all unconstrained problems, for instance. (PRs are welcome)._

So far we used 3 packages from JSO: `NLPModels.jl`, `LinearOperators.jl` and `OptimizationProblems.jl`. It's time to meet another important package.

**CUTEst.jl**

CUTEst, the Constrained and Unconstrained Testing Environment with safe
threads, is a package written in Fortran providing over a thousand problems to
allow testing of Nonlinear Programming solvers. However, CUTEst is hard to use
by first-timers. Just installing it was already hard.
CUTEst.jl provides an interface for CUTEst that is simple to install and use
(comparing to the original).

_Obs.: CUTEst.jl does not work on Windows for now. In fact, there is no plan to
make it work on Windows because "people interested in doing it"∩"people capable
of doing it" = ∅, as far as we've looked. If you are in this set, PRs are
welcome._

To install CUTEst.jl you need to install something manually. Unfortunately,
this is specific for each system. Except for OSX, actually, which is using
[homebrew-cutest](https://github.com/optimizers/homebrew-cutest).

For Linux users, check out [this
page](http://juliasmoothoptimizers.github.io/CUTEst.jl/latest/#Installing-1).
Essentially, we need `libgfortran.so` in a visible place. And it's especially
annoying that some distritions don't put it in a visible place.

With that done, enter

```
Pkg.add("CUTEst")
```

which should install CUTEst.jl 0.1.0.

Yes, it takes some time.

Finally, we start using CUTEst with

```
using CUTEst

nlp = CUTEstModel("ROSENBR")
```

`ROSENBR` is a CUTEst problem, in case you want the list, see
[here](http://www.cuter.rl.ac.uk/Problems/mastsif.html). Keep reading for a way
to select them, though.

Now, let's solve this CUTEst problem with our Newton method.

```
x, fx, ngx = newton(nlp)
```

**Yes, exactly like before!**.

CUTEst is a little more annoying in other aspect also. Like, you can't have two
or more problems open at the same time, and you have to close this problem
before opening a new one. (Again, PRs are welcome).

```
finalize(nlp)
nlp = CUTEstModel("HIMMELBB")
x, fx, ngx = newton(nlp)
finalize(nlp)
```

This allows a simple workflow for writing optimization solvers.

- Write some problems by hand (using `ADNLPModel` or `MathProgNLPModel`);
- Test your solvers with these hand-written problems;
- Repeat last two steps until you believe you're ready to competitive comparison;
- Test with CUTEst problems seamlessly.

Now, let's get back to `hess_op`. Remember that it used Matrix vector products?
Well, CUTEst has separate functions for the product of the Hessian at a point
and a vector. Which means that `hprod` actually computes this product without
having to create the matrix. Which means it is, at least, memory-efficient.
Furthermore, `hess_op` will be created with the `hprod` function, which means
it is also memory-efficient.

Let's look at a huge problem to feel the difference.

```
nlp = CUTEstModel("BOX")
nlp.meta.nvar
```

Let's make a simple comparison

```
function foo1()
  H = hess(nlp, nlp.meta.x0)
  v = ones(nlp.meta.nvar)
  return Hermitian(H, :L) * v
end

function foo2()
  H = hess_op(nlp, nlp.meta.x0)
  v = ones(nlp.meta.nvar)
  return H * v
end

@time w1 = foo1();
@time w2 = foo2();
norm(w1 - w2)
```

Yes, that's a huge difference.

This is a very good reason to use `hess_op` and `hprod`. But let's take a step further.

We can't implement Cholesky using only `hprod`s, so our Newton method would
actually take a long time to reach a solution for the problem above.
To circunvent that, we could try using the Conjugate Gradients Method instead
of Cholesky. This would only use Hessian-vector products.

We arrive on a new package,
[Krylov.jl](https://github.com/JuliaSmoothOptimizers/Krylov.jl), which
implements Krylov methods. In particular, Conjugate Gradients.
This package is also unreleased, so we need to clone it.

```
Pkg.clone("https://github.com/JuliaSmoothOptimizers/Krylov.jl")
```

Consider a simple example

```
using Krylov
A = rand(3,3)
A = A*A'
b = A*ones(3)
cg(A, b)
```

As expected, the system is solver, and the solution is $(1,1,1)$.
But let's do something more.

```
A = -A
cg(A, b)
```

Yes, Krylov does indeed solves the non-positive definite system using Conjugate Gradient.
Well, actually, a variant.

That's not enough tough. Krylov.jl also accepts an additional argument `radius`
to set a trust-region radius.

```
cg(A, b, radius=0.1)
```

Well, as an exercise I suggest you implement a trust-region version of Newton
method, but for now, let's continue with our line-search version.

We know now how `cg` behaves for non-positive definite systems, we can't make
the changes for a new method.

```
function newton2(nlp :: AbstractNLPModel)
  x = nlp.meta.x0
  fx = obj(nlp, x)
  gx = grad(nlp, x)
  ngx = norm(gx)
  while norm(gx) > 1e-6
    Hx = hess_op(nlp, x)
    d, _ = cg(Hx, -gx)
    slope = dot(gx, d)
    if slope >= 0 # Not a descent direction
      d = -gx
      slope = -dot(d,d)
    end
    t = 1.0
    xt = x + t * d
    ft = obj(nlp, xt)
    while ft > fx + 0.5 * t * slope
      t *= 0.5
      xt = x + t * d
      ft = obj(nlp, xt)
    end
    x = xt
    fx = ft
    gx = grad(nlp, x)
    ngx = norm(gx)
  end
  return x, fx, ngx
end
```

Now, running `newton2` on our large problem, we obtain

```
x, fx, ngx = newton2(nlp)
```

Which is the method working very fast. Less that a second here.

---

There is actually another package I'd like to talk about, but it needs some
more work for it to be ready for a release:

**Optimize.jl**

Optimize.jl is a package with solvers. We intend to implement some high quality
solvers in there, but there is actually more to it. We have in there tools to
benchmark packages. These tools should allow the testing of a set of solvers in
a set of problems without much fuss, while creating the comparison information,
including the performance profile.
It also includes, or will include, "parts" of solvers to create your own
solver. Like trust-region and line-search algorithms and auxiliary functions
and types.
Unfortunately, it's not done enough for me to extend on it, and this is already
getting too long.

**End**

I hope you enjoyed this overview of packages.
Subscribe to the RSS feed to keep updated in future tutorials. I intend to talk
about the constrained part of NLPModels soon.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing CUTEst and CUTEst.jl]]></title>
            <link>https://abelsiqueira.github.io/blog/2015-10-01-installing-cutest-and-cutestjl</link>
            <guid>https://abelsiqueira.github.io/blog/2015-10-01-installing-cutest-and-cutestjl</guid>
            <pubDate>Thu, 01 Oct 2015 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# Installing CUTEst and CUTEst.jl

This post will tell you how to install CUTEst using a different tool that makes
it much easier. Also, I'll install CUTEst.jl, the CUTEst interface for Julia.

**Edit:** _Now, CUTEst.jl install CUTEst by itself. Check [this
post](https://abelsiqueira.github.io{{local_prefix}}nlpmodelsjl-cutestjl-and-other-nonlinear-optimization-packages-on-julia/).
Also, for Linux, I've created [this CUTEst
installer](https://github.com/abelsiqueira/linux-cutest), which should be
easier to use. February, 11, 2017_.

**Edit:** _Some corrections were made on February, 15, 2016_.

**Edit:** _Some corrections were made on November, 11, 2015_.

By now you probably know
[CUTEst](http://ccpforge.cse.rl.ac.uk/gf/project/cutest/wiki),
the repository for testing and comparing nonlinear programming algorithms.
It's widely used in the community for some time (considering CUTE and CUTEr,
the previous versions).
If not, this is a good change to test it, using
[Julia](http://www.julialang.org) to play around.
This is a not a post to convince you to use Julia, but I have to say that it is
much easier to use CUTEst on Julia than on MatLab.
So, if you are starting on it, I suggest you take a look.

We will use Homebrew to install CUTEst, for two reasons:

- It's much easier (when you learn it)
- Julia requires shared libraries, that the original installation did not
  provide.

Homebrew is a kind of package manager (such as apt-get, pip, etc.).
For linux, there are many things that we don't need from Homebrew, because you
normally already have a package manager. However, Homebrew is widely used by OSX
users, so it has a lot of packages.
The linux version is [Linuxbrew](https://github.com/Homebrew/linuxbrew).

The installation is quite simple:

- Install brew
- Install CUTEst
- Install CUTEst.jl

I just made these steps and record my terminal, so you can check
[Asciinema](https://asciinema.org/a/27127), or the embedded version on the
bottom of the page. Be warned, though, that I was "cold running" them, so some
parts are very slow.

To install brew, I recommend you check the page. For the impatient,

```
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/linuxbrew/go/install)"
echo 'export PATH="$HOME/.linuxbrew/bin:$PATH"' >> $HOME/.bashrc
source $HOME/.bashrc
sudo apt-get install build-essential subversion
brew doctor
```

To install CUTEst, read the
[tap cutest](https://github.com/optimizers/homebrew-cutest).
Again, for the impatient

```
brew tap optimizers/cutest
brew install cutest
brew install mastsif
for f in archdefs mastsif sifdecode cutest; do \
  echo "source $(brew --prefix $f)/$f.bashrc" >> \
  $HOME/.bashrc; \
done
echo 'export LD_LIBRARY_PATH="$HOME/.linuxbrew/lib:$LD_LIBRARY_PATH"' >> $HOME/.bashrc
source $HOME/.bashrc
```

This should get CUTEst installed.
Notice the `LD_LIBRARY_PATH` variable, which points to where the CUTEst library
will be.

Test it with

```
brew test sifdecode
brew test cutest
```

That's it. You have CUTEst installed to use with Fortran or C.
A can't provide a simple example, because they aren't simple (enough).
I'll now go to Julia, and I recommend you try it.

To install Julia, go to their page, then downloads, then download the
static version of the stable release (or do what you want, I'm not your boss).
Then, in julia, to install
[CUTEst.jl](https://github.com/abelsiqueira/CUTEst.jl),
issue the commands

```
Pkg.clone("https://github.com/abelsiqueira/CUTEst.jl")
Pkg.checkout("CUTEst", "fix/issue4")
```

If nothing goes wrong, then you can play around.
For instance, to open problem HS32 and get the objective function value at point
(2,3), we do

```
using CUTEst
nlp = CUTEstModel("HS32")
f = obj(nlp, [2.0;3.0])
```

If you're familiar with CUTEst, you can use the classic functions `cfn` and
`ufn` too, in the default way (as called from C) or a more Julian way.
This would become too long to explain now, so I'll make a post in a few days (or
months).
If you need it, please contact me.

This concludes the new installation of CUTEst.

**Warning**: Due to current limitations we cannot open two problems at the same
time in CUTEst without the possibility of a segmentation fault.
So, if you need to run cutest for a list of problems, I suggest you use a bash
script to loop over each problem and call your Julia code passing the problem as
an input argument.

Ths embedded Asciinema video is below.

<script type="text/javascript" src="https://asciinema.org/a/27127.js"
id="asciicast-27127" async></script>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CUTEst.jl]]></title>
            <link>https://abelsiqueira.github.io/blog/2015-02-06-cutestjl</link>
            <guid>https://abelsiqueira.github.io/blog/2015-02-06-cutestjl</guid>
            <pubDate>Fri, 06 Feb 2015 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# CUTEst.jl

About an year ago,
[Raniere](http://rgaiacs.com/)
started working on a interface for
[CUTEst](http://ccpforge.cse.rl.ac.uk/gf/project/cutest/wiki/).
He decided to create [ugly](https://github.com/lpoo/ugly),
a repository for CUTEst, but following the Unix procedure for
building packages (`./configure, make, make install`).
Also with ugly, he wanted to enable building a shared library
to be used with Julia.
This approach worked, but maintaining it is troublesome,
since it would require updating and testing of ugly for every
update of CUTEst.

What I decided to do was find a way to create a shared library
from a working CUTEst installation.
This focuses on another principle: passing the blame, er,
I mean, modularity.
My package would simply take a working CUTEst and make a
working shared library from it.
It also served of downloading and installing a new CUTEst
installation, since this would be required for testing.
The work can be found at
[cutest-julia-installer](http://github.com/abelsiqueira/cutest-julia-installer).

The second thing Raniere worked was the interface itself,
which is a module/package for Julia that enables
building a problem from its name,
retrieving its parameters,
and using its mathematical functions
(objective function, gradient, Hessian, constraints,
Jacobian, and so on).
I continued this work, changing the way the problem is built
(to use my shared library),
and translating the core functions to Julia.
With these additions, the usual functions on CUTEst can be
called with little change in Julia.

The next step is to facilitate the use of CUTEst functions
by creating higher-level interfaces.
So, instead of manually verifying if problem is
constrained or not, and then calling
`cfn(st, n, m, x, f, c)` or `ufn(st, n, x, f)`,
to get the objective function value,
one might simply call
`f = obj_fun(prob, x)`.
This should probably be slower,
if the user, for instance, ends up calling two functions
instead of one, but if it increases development time,
then it has server its purpose.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Selecting a Subgroup of CUTEst Problems According to Specific Criteria]]></title>
            <link>https://abelsiqueira.github.io/blog/2015-01-16-selecting-a-subgroup-of-cutest-problems-according-to-specific-criteria</link>
            <guid>https://abelsiqueira.github.io/blog/2015-01-16-selecting-a-subgroup-of-cutest-problems-according-to-specific-criteria</guid>
            <pubDate>Fri, 16 Jan 2015 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# Selecting a Subgroup of CUTEst Problems According to Specific Criteria

For some time now I've been using CUTEst or CUTEr,
and one of the common problems is selecting the problem you
want to use.

Unfortunately, the classification on the site is not updated,
and may contain errors, so I decided to create something,
with low requirements and high reliability, to select problems
according to a criteria.

[This work](https://github.com/abelsiqueira/cute-problem-chooser)
was created before, but used the site's classification as one
of the sources of information for the selection.
Now, I started from scratch, using Python, printing in JSON,
and running only `sifdecode`, and only when needed.

We mantain a JSON file with all information that can be obtained
running `sifdecode` (please correct me if I'm wrong).
This file only need to be updated when the SIF problems are updated.

Currently, I returned to this problem because a colleague needed
unconstrained problems such that the objective function is a sum of
squares, and all variables are free.
According to the classification, the two first letters needed to be
SU, and problems `BARD` and `ARGLALE` satisfied this condition.
However, problem `ARGLALE` is classified as SU, but it is not.
It is actually a problem with objective function 0 (or no objective
function), and with equality contraints only.
Both these forms are different formulations for the Nonlinear Least Squares
problem, but the CUTEst approach to it is very different, because
when they are a sum of squared function norms, we cannot obtain individual
function values and gradient, whereas in the other formulation,
there is already a function to access the individual constraints and gradients.

Hence, we needed to select all problems with no defined objective function,
with equality constraints, and only free variables.
The current implemented version of
[my scripts](https://github.com/abelsiqueira/cute-problem-chooser)
reflect this need.
So, if you need a different criteria met, you will need to hardcode it
using python. This is expected to change soon, if time permits,
to respond to command line arguments and/or user defined configurations
files.

If you are interested in working in this problems,
you can directly access the link above, work and make a pull request,
or e-mail me so we can work out the details of that I expected to make.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CUTEst Com Matlab]]></title>
            <link>https://abelsiqueira.github.io/blog/2015-01-08-cutest-com-matlab</link>
            <guid>https://abelsiqueira.github.io/blog/2015-01-08-cutest-com-matlab</guid>
            <pubDate>Thu, 08 Jan 2015 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[
# CUTEst Com Matlab

No meu [vídeo do YouTube](https://www.youtube.com/watch?v=pM7FmOXHyns),
eu ensinei como se faz para instalar o CUTEst. Hoje estendo a instalação
para instalar o MatLab também, mas para uma instalação mais detalhada,
talvez o vídeo seja mais indicado.

Inicialmente instale o Matlab. Não vou entrar em detalhes, mas atente-se a duas
coisas:

- Algumas versões do matlab não colocam o executável num lugar "visível pelo

```
terminal".
Para resolver, usando o bash, adicione o caminho dos executáveis do MATLAB
ao PATH no arquivo `~/.bashrc`.
Por exemplo, adicionando
```

```
PATH=/usr/local/MATLAB/R20XXc/bin:$PATH
```

- Você vai precisar do `mex` (um link para ele é suficiente) no /bin.

```
Para resolver, pode fazer um link a partir do caminho original
```

```
$ sudo ln -s /usr/local/MATLAB/R20XXc/bin/mex /bin/
```

Depois de instalado o Matlab,
vamos instalar o CUTEst. Você precisará do `subversion` instalado (que
disponibiliza o comando `svn`), e do compilador de fortran.
**A versão do compilador de fortran depende da versão do Matlab.**

|  Versão do Matlab   | Versão do compilador |
| :-----------------: | :------------------: |
|   Antes do R2011a   |         g95          |
|   R2011a - R2013a   |     gfortran-4.4     |
| R2013b ou mais novo |     gfortran-4.7     |

Crie ou escolha uma pasta para as biblioteca do cutest.
A nossa será `$HOME/libraries`.
Nessa pasta baixe os repositórios CUTEst usando o subversion.
Siga os passos da [wiki
oficial](http://ccpforge.cse.rl.ac.uk/gf/project/cutest/wiki/),
ou copie os comandos abaixo para um arquivo `baixacutest.sh`.

```
#!/bin/bash
```

```
cmd="svn checkout -q --username anonymous --password "" --non-interactive --no-auth-cache"
url="http://ccpforge.cse.rl.ac.uk/svn/cutest/"
for name in archdefs sifdecode cutest sif
do
echo "Downloading $name"
$cmd $url/$name/trunk ./$name
done
```

Para executar esse arquivo, rode os comandos

```
$ chmod a+x baixacutest.sh
$ ./baixacutest.sh
```

Entre na pasta `$HOME/libraries/archdefs` e rode o comando
`install_optsuite`.
Responda as perguntas para instalar o CUTEst e sua família.

Depois da instalação, o CUTEst soltará várias informações que
você deve guardar no seu `$HOME/.bashrc`. As minhas
informações estão abaixo. Você pode modificar para corresponder
à sua configuração.

```
LIBS=$HOME/libraries
export ARCHDEFS="$LIBS/archdefs"
export SIFDECODE="$LIBS/sifdecode"
export CUTEST="$LIBS/cutest"
export MASTSIF="$LIBS/sif"
export PATH="$CUTEST/bin:$SIFDECODE/bin:$PATH"
export MANPATH="$CUTEST/man:$SIFDECODE/man:$MANPATH"
export MYARCH="pc64.lnx.gfo"
export MYMATLABARCH="pc64.lnx.gfo"
export MYMATLAB="/usr/local/MATLAB/RXXXX/"
```

Para fazer o Matlab funcionar com o CUTEst, você decodifica o arquivo `SIF`
para o format `mex` do matlab. Daí, você tem que abrir o Matlab naquela pasta,
ou inserir o path dessa pasta.
Aí você usa os comandos do cutest para acessar as propriedades do problema.
O primeiro comando que você vai usar é o

```
prob = cutest_setup()
```

Para acessar a função objetivo, você pode usar

```
f = cutest_obj(x)
[f,g] = cutest_obj(x) % já retorna o gradiente também
```

Para acessar o gradiente, você pode usar

```
g = cutest_grad(x)
```

Além disso, existem outras funções que você pode usar.
A lista está no apêndice B do
Technical Report do CUTEst.

Para testar sua instação, você pode copiar o programinha a seguir,
que tenta encontrar o minimizador de uma função através do método
de máxima descida.

```
function [x,fx,k] = steep(x, f, g)

kmax = 1e4;
alpha = 0.5;
eps = 1e-4;

fx = f(x);
gx = g(x);

k = 1;
while norm(gx) > eps
  t = 1;
  while f(x-t*gx) > fx - alpha*t*dot(gx,gx)
    t = t*0.9;
  end
  x = x - t*gx;
  fx = f(x);
  gx = g(x);
  k = k + 1;
  if k > kmax
    return
  end
end
```

Copie esse conteúdo para um arquivo `steep.m`, e abra o Matlab.
No terminal, vá até a pasta em que está esse arquivo e rode:

```
$ cutest2matlab BARD
```

No matlab, vá até a pasta que está esse arquivo e rode

```
prob = cutest_prob();
[sol, fx, k] = steep(prob.x, @(x) cutest_obj(x), @(x) cutest_grad(x))
```

A solução do problema deve ser perto de `(0.08,1.14,2.33)` e `f = 0.0082`.
]]></content:encoded>
        </item>
    </channel>
</rss>